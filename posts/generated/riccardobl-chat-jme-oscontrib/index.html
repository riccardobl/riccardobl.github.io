<!DOCTYPE html>
<html lang="en-us" translate="no" >

<head>
  <script src="/js/openpgp.js"></script>
  <script src="/js/lnurl-pay.js"></script>
  <script src="/js/qrcode.js"></script>
    <link rel="stylesheet" href="/highlight/styles/railscasts.css">
    <script src="/highlight/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

  <title>RBLB  | chat-jme</title>
  <meta name="viewport" content="width=device-width,minimum-scale=1">
  
  <meta name="generator" content="Hugo 0.109.0">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <script src="/js/script.js"></script>
  

  
  <link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
  

  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,200,0,0" />
  <link rel="stylesheet" href="/css/mobile.css"/><meta name="robots" content="noindex"></head>

<body>
  <progress onload="startCyclingProgressBar()" max=100 value=0 id="pageLoadingProgress"></progress>


   
<fakheader>
    <div id="rblb"></div> 

</fakheader>
<header >
<div>
    <div id="rblb"></div> 
</div>
<div id="board">
    <div>
        <p>
            I am Riccardo Balbo, a freelance developer.
            <br> I develop full stack web applications, software, iot and more.
            <br>
            Feel free to contact me for a quote or for more information.
            
            
            

                <piva>P.IVA 05607610283</piva>

        </p>

    </div>

  

</div>

<div>
    <nav id="rblb">
        <a href="/"><span class="material-symbols-outlined">home</span> Home</a>
        
        <a href="/contacts"><span class="material-symbols-outlined">mail</span> Get in touch</a>
    </nav>
</div>

</header>
 
<main> 
<section class="full">
   
    <article >

    




    <h1 id="chat-jme">CHAT-JME</h1>
<p><img src="https://raw.githubusercontent.com/riccardobl/chat-jme/master/media/sc1.png" alt="chat-jme"></p>
<p>An AI assistant for jMonkeyEngine and related projects.</p>
<p>It knows :</p>
<ul>
<li>all the main documentation of jMonkeyEngine and some prominent projects</li>
<li>the entire source code of the jMonkeyEngine main repo</li>
<li>how to search the forum for basic queries</li>
</ul>
<p>For more details, check the <a href="https://github.com/riccardobl/chat-jme/blob/master/#knowledge-base">knowledge base</a> section.</p>
<h2 id="technologies">Technologies</h2>
<p>To provide the functionality of the bot, the following libraries are used:</p>
<ul>
<li><a href="https://github.com/hwchase17/langchain">ðŸ¦œðŸ”— LangChain</a>: to interface with GPT-3</li>
<li><a href="https://huggingface.co/">ðŸ¤— HuggingFace</a>: inference libraries and models</li>
<li><a href="https://openai.com/api/">OpenAI apis</a>: LLM for text generation</li>
<li><a href="https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2"><del>MiniLM L6 v2</del></a>: <del>fast embeddings</del></li>
<li><a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">all-mpnet-base-v2</a>: embeddings </li>
<li><a href="https://huggingface.co/philschmid/flan-t5-base-samsum">Flan-t5-base-samsum</a>: Summarization </li>
<li><a href="https://github.com/miso-belica/sumy">Sumy</a>: Alternative summarization </li>
<li><a href="https://pypi.org/project/yake/">Yake</a>: keywords extraction </li>
<li><a href="https://libretranslate.com/">LibreTranslate</a>: Multi language support and detection</li>
<li>and more .. Check the <a href="https://github.com/riccardobl/chat-jme/blob/master/requirements.txt">requirements.txt</a> and <a href="https://github.com/riccardobl/chat-jme/blob/master/environment.yml">environment.yml</a> for the full list.</li>
</ul>
<h2 id="knowledge-base">Knowledge base</h2>
<p>The bot extends the knowledge of GPT-3 by embedding pieces of information from the following sources:</p>
<h3 id="static-embeddings">Static embeddings</h3>
<p>Static embeddings are updated periodically and stored in the <a href="https://github.com/riccardobl/chat-jme/blob/master/embeddings/">embeddings/</a> folder in this repo.</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> <a href="https://jmonkeyengine.org">jmonkeyengine.org</a> (partial)</li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://github.com/riccardobl/chat-jme/blob/master/wiki.jmonkeyengine.org">jMonkeyEngine Wiki</a> </li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://github.com/jMonkeyEngine/jmonkeyengine/">jMonkeyEngine source code</a> </li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://stephengold.github.io/Minie/minie">Minie Wiki</a> </li>
<li><input disabled="" type="checkbox"> <a href="https://github.com/riccardobl/chat-jme/blob/master/">Minie source code</a> </li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://github.com/jMonkeyEngine-Contributions/Lemur/wiki">Lemur Wiki</a></li>
<li><input disabled="" type="checkbox"> <a href="https://github.com/riccardobl/chat-jme/blob/master/">Lemur source code</a></li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://github.com/jMonkeyEngine-Contributions/zay-es/wiki">Zay-ES wiki</a></li>
<li><input disabled="" type="checkbox"> <a href="https://github.com/riccardobl/chat-jme/blob/master/">Zay-ES source code</a></li>
<li><input checked="" disabled="" type="checkbox"> <a href="https://github.com/Monkey-Droid/jme3-Simple-Examples">Monkey-Droid/jme3-Simple-Examples</a></li>
</ul>
<h3 id="dynamic-embeddings">Dynamic embeddings</h3>
<p>Dynamic embeddings are generated on the fly for the requested information.</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> <a href="https://hub.jmonkeyengine.org/">jMonkeyEngine Hub</a> (simple search queries based on keywords, cut off: 2023-02-03 )</li>
</ul>
<h2 id="run-without-docker">Run without docker</h2>
<ol>
<li>Install <a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a> or <a href="https://www.anaconda.com/products/individual">Anaconda</a></li>
<li>Clone this repo and cd into it</li>
<li>Create the environment<pre><code class="language-bash">conda env create  -f environment.yml
</code></pre>
</li>
<li>Activate the environment<pre><code class="language-bash">conda activate jmebot
</code></pre>
</li>
<li>Install extra dependencies<pre><code class="language-bash">pip install -r requirements.txt
</code></pre>
5b. If you want to run it on a GPU and you have a CUDA compatible GPU, make sure to have a recent version of <a href="https://developer.nvidia.com/cuda-downloads">CUDA</a> installed and then install the required dependencies <pre><code class="language-bash"># For Ubuntu
sudo apt-get install  build-essential cmake swig libopenblas-dev libpcre3-dev
bash installForCuda.sh # Install the required dependencies (note: this builds faiss-gpu from source, so it will take a while)
</code></pre>
</li>
<li>Export your OpenAI API key<pre><code class="language-bash">export OPENAI_API_KEY="XXXXX"
</code></pre>
</li>
<li>Tweak the config.json file, if you want to run it on a CPU you should change DEVICE to "cpu" and USE_SUMY to true)</li>
<li>Run the bot<pre><code class="language-bash">bash bot.sh
</code></pre>
or regenerate the embeddings<pre><code class="language-bash">bash bot.sh ingest
</code></pre>
</li>
</ol>
<h2 id="usage-with-docker">Usage with Docker</h2>
<p>In a docker host</p>
<h3 id="build-optional">Build (optional)</h3>
<p>The snippets below show how to use the prebuild images on github registry,
If you want to build your own image:</p>
<pre><code class="language-bash"># For cpu
docker build -t chat-jme .

# For cuda
docker build -t chat-jme:cuda . -f Dockerfile.cuda
</code></pre>
<h3 id="run">Run</h3>
<pre><code class="language-bash">mkdir -p /srv/chat-jme/cache
chown -Rf 1000:1000 /srv/chat-jme/cache 

# For CPU
docker run -d --restart=always \
-eOPENAI_API_KEY="XXXXXXXX" \
-v/srv/chat-jme/cache:/home/nonroot/.cache \
-p8080:8080 \
--name="chat-jme" \
ghcr.io/riccardobl/chat-jme/chat-jme:snapshot bot

# For Cuda (recommended)
GPUID="device=GPU-XXXXX"
docker run -d --restart=always \
-eOPENAI_API_KEY="XXXXXXXX" \
-v/srv/chat-jme/cache:/home/nonroot/.cache \
-p8080:8080 \
--gpus $GPUID
--name="chat-jme" \
 ghcr.io/riccardobl/chat-jme/chat-jme:cuda-snapshot bot
</code></pre>
<p><em>NOTE: To use custom static embeddings specify the INDEX_PATH environment variable</em></p>
<p><em>NOTE2: the first run might take some time since it has to download the models.</em></p>
<p><em>NOTE3: If you use the cpu you might need to add --security-opt seccomp=unconfined to the docker command if performances are bad (note that this is not recommended)</em></p>
<h3 id="rebuildupdate-static-embeddings">Rebuild/update static embeddings</h3>
<pre><code class="language-bash">mkdir -p /srv/chat-jme/cache
chown -Rf 1000:1000 /srv/chat-jme/cache 

mkdir -p /srv/chat-jme/embeddings
chown -Rf 1000:1000 /srv/chat-jme/embeddings

docker run -d --restart=always \
-eOPENAI_API_KEY="XXXXXXXX" \
-eINDEX_PATH="/embeddings" \
-v/srv/chat-jme/cache:/home/nonroot/.cache \
-v/srv/chat-jme/embeddings:/embeddings \
--name="chat-jme" \
ghcr.io/riccardobl/chat-jme/chat-jme:snapshot ingest
</code></pre>
<h2 id="api">API</h2>
<h3 id="create-maintain-a-session-should-be-called-periodically">Create maintain a session (should be called periodically)</h3>
<p><strong>POST</strong> /session</p>
<p>REQUEST</p>
<pre><code class="language-json">{
    "sessionSecret":"", // sessionSecret of the session to maintain or nothing to create a new one
    "lang":"en" // || "it" || etc... || "auto",    
}
</code></pre>
<p>RESPONSE</p>
<pre><code class="language-json">{
    "sessionSecret":"XYZ", // sessionSecret of the session
    "helloText":"???", // Text that can be used to initiate a conversation with the bot (in the chosen language)
    "welcomeText": "..." // Hardcoded welcome text in the specified language
}
</code></pre>
<h3 id="ask-something">Ask something</h3>
<p><strong>POST</strong> /query</p>
<p>REQUEST</p>
<pre><code class="language-json">{
    "sessionSecret":"",
    "lang":"en",// || "it" || etc... || "auto",
    "question":"Your question"
}
</code></pre>
<p>RESPONSE</p>
<pre><code class="language-json">{
    "output_text":"???" // Answer to the question
}
</code></pre>
<h3 id="list-all-supported-languages">List all supported languages</h3>
<p><strong>GET</strong> /lang</p>
<p>RESPONSE</p>
<pre><code class="language-json">[
    {
        "name":"English",
        "code":"en"
    },
    {
        "name":"Italian",
        "code":"it"
    },
    ...
]
</code></pre>
<h2 id="frontend-usage-and-configuration">Frontend usage and configuration</h2>
<p>The frontend is server on the 8080 port by default.
It supports some configuration parameters that can be passed as document hash parameters.
Multiple parameters can be concatenated with the <code>&amp;</code> character.</p>
<ul>
<li><strong>lang</strong> the language for questions and answers. (default: en, use auto to get the bot to detect the language automatically)</li>
<li><strong>compact</strong> if true, the bot will be displayed in a compact mode, good for embedding (default: false)</li>
</ul>

            <nav  class="h">
               <a rel="noopener noreferrer" href="https://github.com/riccardobl/chat-jme" target="_blank"><i class="fab fa-github"></i> Github page</a>
            
                <a rel="noopener noreferrer" href="https://chat-jme.frk.wf" target="_blank">
                <i class="fas fa-home"></i> Homepage</a>
                 </nav>


    <time datetime="2025-10-11 05:58:15 &#43;0000 UTC">11 October 2025</time>

<nav class="tags">
    
    
    
    <a class="Python" href="/tags/python/">#Python</a>
    
    
    
    
    <a class="opensource-contrib" href="/tags/opensource-contrib/">#opensource-contrib</a>
    
    
    
    
    <a class="ai" href="/tags/ai/">#ai</a>
    
    
    
    
    <a class="gpt" href="/tags/gpt/">#gpt</a>
    
    
    
    
    <a class="gpt3" href="/tags/gpt3/">#gpt3</a>
    
    
    
    
    <a class="jmonkeyengine" href="/tags/jmonkeyengine/">#jmonkeyengine</a>
    
    
    
    
    <a class="langchain" href="/tags/langchain/">#langchain</a>
    
    
    
    
    <a class="openai" href="/tags/openai/">#openai</a>
    
    
</nav>      

</article>      

</section>

</main>
 
</body>

</html>
